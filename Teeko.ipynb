{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy import inf\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "move_dict = {\n",
    "  \"A\": 0, \"a\": 0,\n",
    "  \"B\": 1, \"b\": 1,\n",
    "  \"C\": 2, \"c\": 2,\n",
    "  \"D\": 3, \"d\": 3,\n",
    "  \"E\": 4, \"e\": 4,\n",
    "}\n",
    "\n",
    "class Teeko:\n",
    "    def __init__(self, player1, player2):\n",
    "        self.player1 = (player1, 1)  # Black Player\n",
    "        self.player2 = (player2, 2)  # Red Player\n",
    "        self.board = np.zeros((5,5))\n",
    "        self.turn = 0\n",
    "        self.current_player = self.player1\n",
    "    \n",
    "    def set_player(self, player):\n",
    "        if player == 1:\n",
    "            self.current_player = self.player1\n",
    "        else: self.current_player = self.player2\n",
    "    \n",
    "    def switch_player(self):\n",
    "        if self.current_player == self.player1:\n",
    "            self.current_player = self.player2\n",
    "        else: self.current_player = self.player1\n",
    "        self.turn += 1\n",
    "        \n",
    "    def move_translator(self, selected):       #A5, B6 etc.\n",
    "        yPos = selected[0]\n",
    "        xPos = int(selected[1]) - 1\n",
    "        return (move_dict[yPos], xPos)\n",
    "\n",
    "    def make_a_move(self, selected, move = None):       # selected recibe posiciones reales tupla, move recibe la dirección  # move\n",
    "        y, x = selected\n",
    "        valid_move = True\n",
    "        if self.board[y][x] != self.current_player[1] and move != None:\n",
    "            valid_move = False\n",
    "            return valid_move, selected\n",
    "        if move is not None:\n",
    "            for pos in move:\n",
    "                if pos == \"u\" and y > 0:\n",
    "                    y -= 1\n",
    "                elif pos == \"d\" and y < 4:\n",
    "                    y += 1\n",
    "                elif pos == \"r\" and x < 4:\n",
    "                    x += 1 \n",
    "                elif pos == \"l\" and x > 0: \n",
    "                    x -= 1\n",
    "                else: \n",
    "                    valid_move = False\n",
    "        if valid_move and self.board[y][x] == 0:\n",
    "            self.board[selected[0]][selected[1]] = 0\n",
    "            limit = x >=0 and x < 5 and y >= 0 and y < 5\n",
    "            if limit:\n",
    "                selected = (y, x)\n",
    "                self.board[selected[0]][selected[1]] = self.current_player[1]\n",
    "            else: \n",
    "                print(\"Limites superados o posición ocupada\")\n",
    "                valid_move = False\n",
    "        else: \n",
    "            print(\"Movimiento no válido, vuelva a intentarlo\")   \n",
    "            valid_move = False\n",
    "            \n",
    "        return valid_move, selected\n",
    "        \n",
    "    def check_horizontal(self, y):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for row in self.board[y]:\n",
    "            if row == self.current_player[1]:\n",
    "                count += 1\n",
    "            else: count = 0\n",
    "            if count == 4:\n",
    "                winner = True\n",
    "        return winner\n",
    "\n",
    "    def check_vertical(self, x):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for col in range(5):\n",
    "            if self.board[col][x] == self.current_player[1]:\n",
    "                count += 1\n",
    "            else: count = 0\n",
    "            if count == 4:\n",
    "                winner = True\n",
    "        return winner\n",
    "    \n",
    "    def check_diagonal(self, matrix):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for k in range(3):\n",
    "            arr = np.diag(matrix, k - 1)\n",
    "            for x in arr:\n",
    "                if x == self.current_player[1]:\n",
    "                    count += 1\n",
    "                else: count = 0\n",
    "                if count == 4:\n",
    "                    winner = True\n",
    "            if winner:\n",
    "                break\n",
    "        return winner\n",
    "    \n",
    "    def check_square(self, x, y):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for i in range (2):\n",
    "            if y + 1 < 5 and x + i < 5:\n",
    "                if self.board[y][x + i] == self.current_player[1]:\n",
    "                    count += 1\n",
    "                if self.board[y + 1][x + i] == self.current_player[1]:\n",
    "                    count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y - 1 >= 0 and x + i < 5:\n",
    "                    if self.board[y][x + i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y - 1][x + i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y + 1 < 5 and x - i >= 0:\n",
    "                    if self.board[y][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y + 1][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y - 1 >= 0 and x - i >= 0:\n",
    "                    if self.board[y][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y - 1][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count == 4:\n",
    "            winner = True\n",
    "        return winner\n",
    "\n",
    "    def check_winner(self, last_position): #0,1 2,0\n",
    "        y, x = last_position\n",
    "        count = 0\n",
    "        winner = False\n",
    "        winner = self.check_horizontal(y)\n",
    "        if not winner:\n",
    "            winner = self.check_vertical(x)\n",
    "        if not winner:\n",
    "            winner = self.check_diagonal(self.board)\n",
    "        if not winner:\n",
    "            winner = self.check_diagonal(np.fliplr(self.board))\n",
    "        if not winner:\n",
    "            winner = self.check_square(x, y)\n",
    "        return winner  \n",
    "    \n",
    "    def get_position(self):\n",
    "        arr_pos = []\n",
    "        phase1 = False\n",
    "        if np.count_nonzero(self.board > 0) != 8:\n",
    "            phase1 = True\n",
    "        for y in range(5):\n",
    "            for x in range(5):\n",
    "                if phase1:\n",
    "                    if self.board[y][x] == 0:\n",
    "                        arr_pos.append((y,x))\n",
    "                else:\n",
    "                    if self.board[y][x] == self.current_player[1]:\n",
    "                        arr_pos.append((y,x))\n",
    "        return arr_pos\n",
    "    \n",
    "    def get_actions(self, selected):\n",
    "        y, x = selected\n",
    "        actions = ['u', 'd', 'l', 'r', 'ul', 'ur', 'dl', 'dr']\n",
    "        valid_move = True\n",
    "        valid_actions = []\n",
    "        if np.count_nonzero(self.board > 0) != 8:\n",
    "            return [None]\n",
    "        for action in actions:\n",
    "            valid_move = True\n",
    "            y, x = selected\n",
    "            for pos in action:\n",
    "                if pos == \"u\" and y > 0:\n",
    "                    y -= 1\n",
    "                elif pos == \"d\" and y < 4:\n",
    "                    y += 1\n",
    "                elif pos == \"r\" and x < 4:\n",
    "                    x += 1 \n",
    "                elif pos == \"l\" and x > 0: \n",
    "                    x -= 1\n",
    "                else: \n",
    "                    valid_move = False\n",
    "            if valid_move and self.board[y][x] == 0:\n",
    "                valid_actions.append(action)\n",
    "        return valid_actions\n",
    "    \n",
    "    def heuristic(self, position):\n",
    "        strength = 0\n",
    "        mat = [[4,6,5,6,4],[6,10,10,10,6],[5,10,12,10,5],[6,10,10,10,6],[4,6,5,6,4]]\n",
    "        \n",
    "        for y in range(5):\n",
    "            for x in range(5):\n",
    "                if self.board[y][x] == self.player1[1]:\n",
    "                    strength += mat[y][x]\n",
    "                if self.board[y][x] == self.player2[1]:\n",
    "                    strength -= mat[y][x]\n",
    "        if self.current_player[0] == \"MAX\":\n",
    "            strength -= self.turn * 2\n",
    "        if self.current_player[0] == \"MIN\":\n",
    "            strength += self.turn * 2\n",
    "        if self.check_winner(position):\n",
    "            if self.current_player[0] == \"MAX\":\n",
    "                strength += 100\n",
    "            if self.current_player[0] == \"MIN\":\n",
    "                strength -= 100\n",
    "        return strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax Algorithm\n",
    "\n",
    "def minmax_decision(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value(copyGame, selected)\n",
    "                values.append(value)\n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value(copyGame,selected)\n",
    "                values.append(value)\n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "\n",
    "def min_value(game, last_position):\n",
    "    actions = []\n",
    "    value = inf\n",
    "    if game.check_winner(last_position):\n",
    "        value = game.heuristic(last_position) #nos falta la heurística\n",
    "        game.switch_player()\n",
    "    else:\n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min(value, max_value(copyGame, selected))\n",
    "    return value\n",
    "\n",
    "def max_value(game, last_position):\n",
    "    actions = []\n",
    "    value = -inf\n",
    "    if game.check_winner(last_position):\n",
    "        value = game.heuristic(last_position) #nos falta la heurística\n",
    "        game.switch_player()\n",
    "    else:\n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions: \n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max(value, min_value(copyGame, selected))\n",
    "    return value\n",
    "\n",
    "def min(value1, value2): #return the minimum value\n",
    "    if value1 < value2:\n",
    "        return value1\n",
    "    else:\n",
    "        return value2\n",
    "\n",
    "def max(value1, value2): #return the max value\n",
    "    if value1 > value2:\n",
    "        return value1\n",
    "    else:\n",
    "        return value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha Beta Pruning Algorithm\n",
    "\n",
    "def alpha_beta_search(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_pruning(copyGame, selected,-inf, inf)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_pruning(copyGame, selected,-inf, inf)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_pruning(self, game, last_position, alpha, beta):\n",
    "    actions = []\n",
    "    v = inf\n",
    "    if game.check_winner(last_position):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_pruning(copyGame, selected,alpha, beta))\n",
    "                if v <= alpha:\n",
    "                    return v\n",
    "                beta = min(beta,v)\n",
    "    return v\n",
    "\n",
    "def max_value_pruning(self, game, last_position, alpha, beta):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if game.check_winner(last_position):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_pruning(copyGame, selected,alpha, beta))\n",
    "                if v >= beta:\n",
    "                    return v\n",
    "                alpha = max(alpha,v)\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax with depth Algorithm (w/o Alpha Beta Pruning)\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "def min_max_with_depth_no_ABP(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_with_depth_no_ABP(copyGame, selected, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_with_depth_no_ABP(copyGame, selected, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_with_depth_no_ABP(game, last_position, depth):    \n",
    "    actions = []\n",
    "    v = inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_with_depth_no_ABP(copyGame, selected, depth + 1))\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def max_value_with_depth_no_ABP(game, last_position, depth):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_with_depth_no_ABP(copyGame, selected, depth + 1)) \n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def cut_off(game, last_position, depth):\n",
    "    return depth == max_depth or game.check_winner(last_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax with depth Algorithm (w/ Alpha Beta Pruning)\n",
    "\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "def min_max_with_depth(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_with_depth(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_with_depth(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_with_depth(game, last_position, alpha, beta, depth):    \n",
    "    actions = []\n",
    "    v = inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_with_depth(copyGame, selected,alpha, beta, depth + 1))\n",
    "                if v <= alpha:\n",
    "                    return v\n",
    "                beta = min(beta,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def max_value_with_depth(game, last_position, alpha, beta, depth):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_with_depth(copyGame, selected,alpha, beta, depth + 1)) \n",
    "                if v >= beta:\n",
    "                    return v\n",
    "                alpha = max(alpha,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def cut_off(game, last_position, depth):\n",
    "    return depth == max_depth or game.check_winner(last_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax with depth Algorithm (w/ Alpha Beta Pruning and shuffle)\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "def min_max_with_depth_shuffle(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    random.shuffle(mark_position)\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            random.shuffle(actions)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_with_depth_shuffle(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_with_depth_shuffle(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_with_depth_shuffle(game, last_position, alpha, beta, depth):    \n",
    "    actions = []\n",
    "    v = inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        random.shuffle(mark_position)\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            random.shuffle(actions)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_with_depth_shuffle(copyGame, selected,alpha, beta, depth + 1))\n",
    "                if v <= alpha:\n",
    "                    return v\n",
    "                beta = min(beta,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def max_value_with_depth_shuffle(game, last_position, alpha, beta, depth):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        random.shuffle(mark_position)\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            random.shuffle(actions)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_with_depth_shuffle(copyGame, selected,alpha, beta, depth + 1)) \n",
    "                if v >= beta:\n",
    "                    return v\n",
    "                alpha = max(alpha,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def cut_off(game, last_position, depth):\n",
    "    return depth == max_depth or game.check_winner(last_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juego\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "    \n",
    "def plot_game(game):\n",
    "    plot.matshow(game.board)\n",
    "    colors = 'white black red'.split()\n",
    "    cmap = matplotlib.colors.ListedColormap(colors, name='colors', N=None)\n",
    "    plot.title('Gameboard')\n",
    "    plot.xticks([0,1,2,3,4], [\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    plot.yticks([0,1,2,3,4], [\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "    plot.imshow(game.board, cmap=cmap)\n",
    "    plot.show()\n",
    "\n",
    "def order_selection(game):\n",
    "    print(\"Select your color: \")\n",
    "    print(\"1 .- Black pieces (First Player)\")\n",
    "    print(\"2 .- Red pieces (Second Player)\")\n",
    "    player_selected = int(input())\n",
    "    clear_output(wait=False)\n",
    "    return player_selected\n",
    "\n",
    "def gameloop():\n",
    "    winner_found = False\n",
    "    game = Teeko(\"MAX\", \"MIN\")\n",
    "    player_selected = order_selection(game)\n",
    "    turn = 1\n",
    "    while winner_found != True:\n",
    "        if turn > 8:\n",
    "            if player_selected != game.current_player[1]:\n",
    "                move, selected_piece = min_max_with_depth_shuffle(deepcopy(game))\n",
    "                valid_move, selected = game.make_a_move(selected_piece, move)\n",
    "                winner_found = game.check_winner(selected)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                print(f\"== Algoritmo ==\")\n",
    "                print(f\"Ficha seleccionada: {selected_piece}\")\n",
    "                print(f\"Movimiento: {move}\")\n",
    "            else:\n",
    "                print(f\"== Jugador ==\")\n",
    "                print(f\"Ingresar movimiento\")\n",
    "                selected_piece = input()\n",
    "                move = input()\n",
    "                selected_translated = game.move_translator(selected_piece)\n",
    "                valid_move, selected = game.make_a_move(selected_translated, move)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                time.sleep(0.01)\n",
    "                winner_found = game.check_winner(selected)\n",
    "        else:\n",
    "            if player_selected == game.current_player[1]:\n",
    "                clear_output(wait=False)\n",
    "                print(f\"Ingresar movimiento\")\n",
    "                plot_game(game)\n",
    "                move = input()\n",
    "                move_translated = game.move_translator(move)\n",
    "                valid_move, selected = game.make_a_move(move_translated)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                winner_found = game.check_winner(move_translated)\n",
    "                \n",
    "                time.sleep(0.01)\n",
    "            else:\n",
    "                move, selected_piece = min_max_with_depth_shuffle(deepcopy(game))\n",
    "                valid_move, selected = game.make_a_move(selected_piece)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                winner_found = game.check_winner(selected)\n",
    "\n",
    "        if not winner_found and valid_move:                             #Si el jugador realiza un movimiento invalido repite su turno\n",
    "                game.switch_player()\n",
    "                turn += 1\n",
    "    print(f\"El jugador ganador es: {game.current_player}\")\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingresar movimiento\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Downloads\\Sistemas Inteligentes\\Assignment 3\\Teeko.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gameloop()\n",
      "\u001b[1;32me:\\Downloads\\Sistemas Inteligentes\\Assignment 3\\Teeko.ipynb Cell 10\u001b[0m in \u001b[0;36mgameloop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m plot_game(game)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m move \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m move_translated \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39;49mmove_translator(move)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m valid_move, selected \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mmake_a_move(move_translated)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32me:\\Downloads\\Sistemas Inteligentes\\Assignment 3\\Teeko.ipynb Cell 10\u001b[0m in \u001b[0;36mTeeko.move_translator\u001b[1;34m(self, selected)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmove_translator\u001b[39m(\u001b[39mself\u001b[39m, selected):       \u001b[39m#A5, B6 etc.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     yPos \u001b[39m=\u001b[39m selected[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     xPos \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(selected[\u001b[39m1\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Downloads/Sistemas%20Inteligentes/Assignment%203/Teeko.ipynb#X36sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (move_dict[yPos], xPos)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "gameloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "003ea14c466a182c11296508987618b215c1bc2b82b8507cd4cdbb7452f6e9d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
