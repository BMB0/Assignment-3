{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 espacios conectados con lineas verticales, horizontales y diagonales\n",
    "\n",
    "4 fichas negras y 4 piezas rojas\n",
    "\n",
    "Si un jugador forma una linea de 4 fichas Gana la partida (Horizontal, Diagonal y Vertical)\n",
    "\n",
    "Si un jugador forma un cuadrado Gana la partida\n",
    "\n",
    "Una vez asignadas las 4 piezas el jugador puede seleccionar una y moverla a una casilla sin asignacion\n",
    "\n",
    "link\n",
    "\n",
    "los jugadores sortean quien comienza, por defecto comienza el negro y se alternan entre sí\n",
    "\n",
    "####################################primera fase####################################################################\n",
    "\n",
    "En la primera parte los jugadores ponen sus marcadores, y cada marcador ocupa un campo, para el final de esta fase hay 8 fichas en el tablero, 4 negras y 4 rojas\n",
    "\n",
    "Es posible ganar en la primera fase, si nadie gana, se pasa a la segunda fase\n",
    "\n",
    "####################################segunda fase####################################################################\n",
    "\n",
    "No se puede saltar turnos\n",
    "\n",
    "en cada turno se puede mover las fichas en un campo adyacente vacio, ya sea vertical, horizontal o diagonal\n",
    "\n",
    "####################################objective#######################################################################\n",
    "\n",
    "organizar las fichas hasta formar un Teeko, existen 44 Teekos distintos, las mismas se dividen en verticales, horizontales , diagonales y cuadradas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do List:\n",
    "\n",
    "- Mejorar el codigo en general\n",
    "- Comparar algoritmos y plottear resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy import inf\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "move_dict = {\n",
    "  \"A\": 0, \"a\": 0,\n",
    "  \"B\": 1, \"b\": 1,\n",
    "  \"C\": 2, \"c\": 2,\n",
    "  \"D\": 3, \"d\": 3,\n",
    "  \"E\": 4, \"e\": 4,\n",
    "}\n",
    "\n",
    "class Teeko:\n",
    "    def __init__(self, player1, player2):\n",
    "        self.player1 = (player1, 1)  # Black Player\n",
    "        self.player2 = (player2, 2)  # Red Player\n",
    "        self.board = np.zeros((5,5))\n",
    "        self.turn = 0\n",
    "        self.current_player = self.player1\n",
    "    \n",
    "    def set_player(self, player):\n",
    "        if player == 1:\n",
    "            self.current_player = self.player1\n",
    "        else: self.current_player = self.player2\n",
    "    \n",
    "    def switch_player(self):\n",
    "        if self.current_player == self.player1:\n",
    "            self.current_player = self.player2\n",
    "        else: self.current_player = self.player1\n",
    "        self.turn += 1\n",
    "        \n",
    "    def move_translator(self, selected):       #A5, B6 etc.\n",
    "        yPos = selected[0]\n",
    "        xPos = int(selected[1]) - 1\n",
    "        return (move_dict[yPos], xPos)\n",
    "\n",
    "    def make_a_move(self, selected, move = None):       # selected recibe posiciones reales tupla, move recibe la dirección  # move\n",
    "        y, x = selected\n",
    "        valid_move = True\n",
    "        if self.board[y][x] != self.current_player[1] and move != None:\n",
    "            valid_move = False\n",
    "            return valid_move, selected\n",
    "        if move is not None:\n",
    "            for pos in move:\n",
    "                if pos == \"u\" and y > 0:\n",
    "                    y -= 1\n",
    "                elif pos == \"d\" and y < 4:\n",
    "                    y += 1\n",
    "                elif pos == \"r\" and x < 4:\n",
    "                    x += 1 \n",
    "                elif pos == \"l\" and x > 0: \n",
    "                    x -= 1\n",
    "                else: \n",
    "                    valid_move = False\n",
    "        if valid_move and self.board[y][x] == 0:\n",
    "            self.board[selected[0]][selected[1]] = 0\n",
    "            limit = x >=0 and x < 5 and y >= 0 and y < 5\n",
    "            if limit:\n",
    "                selected = (y, x)\n",
    "                self.board[selected[0]][selected[1]] = self.current_player[1]\n",
    "            else: \n",
    "                print(\"Limites superados o posición ocupada\")\n",
    "                valid_move = False\n",
    "        else: \n",
    "            print(\"Movimiento no válido, vuelva a intentarlo\")   \n",
    "            valid_move = False\n",
    "            \n",
    "        return valid_move, selected\n",
    "        \n",
    "    def check_horizontal(self, y):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for row in self.board[y]:\n",
    "            if row == self.current_player[1]:\n",
    "                count += 1\n",
    "            else: count = 0\n",
    "            if count == 4:\n",
    "                winner = True\n",
    "        return winner\n",
    "\n",
    "    def check_vertical(self, x):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for col in range(5):\n",
    "            if self.board[col][x] == self.current_player[1]:\n",
    "                count += 1\n",
    "            else: count = 0\n",
    "            if count == 4:\n",
    "                winner = True\n",
    "        return winner\n",
    "    \n",
    "    def check_diagonal(self, matrix):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for k in range(3):\n",
    "            arr = np.diag(matrix, k - 1)\n",
    "            for x in arr:\n",
    "                if x == self.current_player[1]:\n",
    "                    count += 1\n",
    "                else: count = 0\n",
    "                if count == 4:\n",
    "                    winner = True\n",
    "            if winner:\n",
    "                break\n",
    "        return winner\n",
    "    \n",
    "    def check_square(self, x, y):\n",
    "        winner = False\n",
    "        count = 0\n",
    "        for i in range (2):\n",
    "            if y + 1 < 5 and x + i < 5:\n",
    "                if self.board[y][x + i] == self.current_player[1]:\n",
    "                    count += 1\n",
    "                if self.board[y + 1][x + i] == self.current_player[1]:\n",
    "                    count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y - 1 >= 0 and x + i < 5:\n",
    "                    if self.board[y][x + i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y - 1][x + i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y + 1 < 5 and x - i >= 0:\n",
    "                    if self.board[y][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y + 1][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count != 4:\n",
    "            count = 0\n",
    "            for i in range (2):\n",
    "                if y - 1 >= 0 and x - i >= 0:\n",
    "                    if self.board[y][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "                    if self.board[y - 1][x - i] == self.current_player[1]:\n",
    "                        count += 1\n",
    "        if count == 4:\n",
    "            winner = True\n",
    "        return winner\n",
    "\n",
    "    def check_winner(self, last_position): #0,1 2,0\n",
    "        y, x = last_position\n",
    "        count = 0\n",
    "        winner = False\n",
    "        winner = self.check_horizontal(y)\n",
    "        if not winner:\n",
    "            winner = self.check_vertical(x)\n",
    "        if not winner:\n",
    "            winner = self.check_diagonal(self.board)\n",
    "        if not winner:\n",
    "            winner = self.check_diagonal(np.fliplr(self.board))\n",
    "        if not winner:\n",
    "            winner = self.check_square(x, y)\n",
    "        return winner  \n",
    "    \n",
    "    def get_position(self):\n",
    "        arr_pos = []\n",
    "        phase1 = False\n",
    "        if np.count_nonzero(self.board > 0) != 8:\n",
    "            phase1 = True\n",
    "        for y in range(5):\n",
    "            for x in range(5):\n",
    "                if phase1:\n",
    "                    if self.board[y][x] == 0:\n",
    "                        arr_pos.append((y,x))\n",
    "                else:\n",
    "                    if self.board[y][x] == self.current_player[1]:\n",
    "                        arr_pos.append((y,x))\n",
    "        return arr_pos\n",
    "    \n",
    "    def get_actions(self, selected):\n",
    "        y, x = selected\n",
    "        actions = ['u', 'd', 'l', 'r', 'ul', 'ur', 'dl', 'dr']\n",
    "        valid_move = True\n",
    "        valid_actions = []\n",
    "        if np.count_nonzero(self.board > 0) != 8:\n",
    "            return [None]\n",
    "        for action in actions:\n",
    "            valid_move = True\n",
    "            y, x = selected\n",
    "            for pos in action:\n",
    "                if pos == \"u\" and y > 0:\n",
    "                    y -= 1\n",
    "                elif pos == \"d\" and y < 4:\n",
    "                    y += 1\n",
    "                elif pos == \"r\" and x < 4:\n",
    "                    x += 1 \n",
    "                elif pos == \"l\" and x > 0: \n",
    "                    x -= 1\n",
    "                else: \n",
    "                    valid_move = False\n",
    "            if valid_move and self.board[y][x] == 0:\n",
    "                valid_actions.append(action)\n",
    "        return valid_actions\n",
    "    \n",
    "    def heuristic(self, position):\n",
    "        strength = 0\n",
    "        mat = [[4,6,5,6,4],[6,10,10,10,6],[5,10,12,10,5],[6,10,10,10,6],[4,6,5,6,4]]\n",
    "        \n",
    "        for y in range(5):\n",
    "            for x in range(5):\n",
    "                if self.board[y][x] == self.player1[1]:\n",
    "                    strength += mat[y][x]\n",
    "                if self.board[y][x] == self.player2[1]:\n",
    "                    strength -= mat[y][x]\n",
    "        if self.current_player[0] == \"MAX\":\n",
    "            strength -= self.turn * 2\n",
    "        if self.current_player[0] == \"MIN\":\n",
    "            strength += self.turn * 2\n",
    "        if self.check_winner(position):\n",
    "            if self.current_player[0] == \"MAX\":\n",
    "                strength += 100\n",
    "            if self.current_player[0] == \"MIN\":\n",
    "                strength -= 100\n",
    "        return strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax Algorithm\n",
    "\n",
    "def minmax_decision(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value(copyGame, selected)\n",
    "                values.append(value)\n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value(copyGame,selected)\n",
    "                values.append(value)\n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "\n",
    "def min_value(game, last_position):\n",
    "    actions = []\n",
    "    value = inf\n",
    "    if game.check_winner(last_position):\n",
    "        value = game.heuristic(last_position) #nos falta la heurística\n",
    "        game.switch_player()\n",
    "    else:\n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min(value, max_value(copyGame, selected))\n",
    "    return value\n",
    "\n",
    "def max_value(game, last_position):\n",
    "    actions = []\n",
    "    value = -inf\n",
    "    if game.check_winner(last_position):\n",
    "        value = game.heuristic(last_position) #nos falta la heurística\n",
    "        game.switch_player()\n",
    "    else:\n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions: \n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max(value, min_value(copyGame, selected))\n",
    "    return value\n",
    "\n",
    "def min(value1, value2): #return the minimum value\n",
    "    if value1 < value2:\n",
    "        return value1\n",
    "    else:\n",
    "        return value2\n",
    "\n",
    "def max(value1, value2): #return the max value\n",
    "    if value1 > value2:\n",
    "        return value1\n",
    "    else:\n",
    "        return value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha Beta Pruning Algorithm\n",
    "\n",
    "def alpha_beta_search(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_pruning(copyGame, selected,-inf, inf)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_pruning(copyGame, selected,-inf, inf)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_pruning(self, game, last_position, alpha, beta):\n",
    "    actions = []\n",
    "    v = inf\n",
    "    if game.check_winner(last_position):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_pruning(copyGame, selected,alpha, beta))\n",
    "                if v <= alpha:\n",
    "                    return v\n",
    "                beta = min(beta,v)\n",
    "    return v\n",
    "\n",
    "def max_value_pruning(self, game, last_position, alpha, beta):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if game.check_winner(last_position):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_pruning(copyGame, selected,alpha, beta))\n",
    "                if v >= beta:\n",
    "                    return v\n",
    "                alpha = max(alpha,v)\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax with depth Algorithm (w/o Alpha Beta Pruning)\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "def min_max_with_depth_no_ABP(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_with_depth_no_ABP(copyGame, selected, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_with_depth_no_ABP(copyGame, selected, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_with_depth_no_ABP(game, last_position, depth):    \n",
    "    actions = []\n",
    "    v = inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_with_depth_no_ABP(copyGame, selected, depth + 1))\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def max_value_with_depth_no_ABP(game, last_position, depth):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_with_depth_no_ABP(copyGame, selected, depth + 1)) \n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def cut_off(game, last_position, depth):\n",
    "    return depth == max_depth or game.check_winner(last_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimax with depth Algorithm (w/ Alpha Beta Pruning)\n",
    "\n",
    "\n",
    "max_depth = 3\n",
    "\n",
    "def min_max_with_depth(game):  #player MIN MAX, game es de la clase Teeko\n",
    "    values = []\n",
    "    i = 0\n",
    "    mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "    actions = []\n",
    "    moves = []\n",
    "    pieces = []\n",
    "    if game.current_player[0] == \"MAX\":\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = min_value_with_depth(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmax(values)\n",
    "    else:\n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                value = max_value_with_depth(copyGame, selected,-inf, inf, 0)\n",
    "                values.append(value) \n",
    "                moves.append(action)\n",
    "                pieces.append(mark)\n",
    "        i = np.argmin(values)\n",
    "    return moves[i], pieces[i]\n",
    "\n",
    "def min_value_with_depth(game, last_position, alpha, beta, depth):    \n",
    "    actions = []\n",
    "    v = inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = min(v, max_value_with_depth(copyGame, selected,alpha, beta, depth + 1))\n",
    "                if v <= alpha:\n",
    "                    return v\n",
    "                beta = min(beta,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def max_value_with_depth(game, last_position, alpha, beta, depth):\n",
    "    actions = []\n",
    "    v = -inf\n",
    "    if cut_off(game, last_position, depth):\n",
    "        v = game.heuristic(last_position)\n",
    "        game.switch_player()\n",
    "        return v\n",
    "    else: \n",
    "        game.switch_player()\n",
    "        mark_position = game.get_position() # el get devuelve un array de tuplas de las posiciones de todas las fichas del current_player \n",
    "        for mark in mark_position:\n",
    "            actions = game.get_actions(mark)\n",
    "            for action in actions:\n",
    "                copyGame = deepcopy(game)\n",
    "                b, selected = copyGame.make_a_move(mark, action)\n",
    "                v = max(v, min_value_with_depth(copyGame, selected,alpha, beta, depth + 1)) \n",
    "                if v >= beta:\n",
    "                    return v\n",
    "                alpha = max(alpha,v)\n",
    "    game.switch_player()\n",
    "    return v\n",
    "\n",
    "def cut_off(game, last_position, depth):\n",
    "    return depth == max_depth or game.check_winner(last_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juego\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "    \n",
    "def plot_game(game):\n",
    "    plot.matshow(game.board)\n",
    "    colors = 'white black red'.split()\n",
    "    cmap = matplotlib.colors.ListedColormap(colors, name='colors', N=None)\n",
    "    plot.title('Gameboard')\n",
    "    plot.xticks([0,1,2,3,4], [\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    plot.yticks([0,1,2,3,4], [\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "    plot.imshow(game.board, cmap=cmap)\n",
    "    plot.show()\n",
    "\n",
    "def order_selection(game):\n",
    "    print(\"Select your color: \")\n",
    "    print(\"1 .- Black pieces (First Player)\")\n",
    "    print(\"2 .- Red pieces (Second Player)\")\n",
    "    player_selected = int(input())\n",
    "    clear_output(wait=False)\n",
    "    return player_selected\n",
    "\n",
    "def gameloop():\n",
    "    winner_found = False\n",
    "    game = Teeko(\"MAX\", \"MIN\")\n",
    "    player_selected = order_selection(game)\n",
    "    turn = 1\n",
    "    while winner_found != True:\n",
    "        if turn > 8:\n",
    "            if player_selected != game.current_player[1]:\n",
    "                move, selected_piece = min_max_with_depth(deepcopy(game))\n",
    "                valid_move, selected = game.make_a_move(selected_piece, move)\n",
    "                winner_found = game.check_winner(selected)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                print(f\"== Algoritmo ==\")\n",
    "                print(f\"Ficha seleccionada: {selected_piece}\")\n",
    "                print(f\"Movimiento: {move}\")\n",
    "            else:\n",
    "                print(f\"== Jugador ==\")\n",
    "                print(f\"Ingresar movimiento\")\n",
    "                selected_piece = input()\n",
    "                move = input()\n",
    "                selected_translated = game.move_translator(selected_piece)\n",
    "                valid_move, selected = game.make_a_move(selected_translated, move)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                time.sleep(0.01)\n",
    "                winner_found = game.check_winner(selected)\n",
    "        else:\n",
    "            if player_selected == game.current_player[1]:\n",
    "                clear_output(wait=False)\n",
    "                print(f\"Ingresar movimiento\")\n",
    "                plot_game(game)\n",
    "                move = input()\n",
    "                move_translated = game.move_translator(move)\n",
    "                valid_move, selected = game.make_a_move(move_translated)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                winner_found = game.check_winner(move_translated)\n",
    "                \n",
    "                time.sleep(0.01)\n",
    "            else:\n",
    "                move, selected_piece = min_max_with_depth(deepcopy(game))\n",
    "                valid_move, selected = game.make_a_move(selected_piece)\n",
    "                clear_output(wait=False)\n",
    "                plot_game(game)\n",
    "                winner_found = game.check_winner(selected)\n",
    "\n",
    "        if not winner_found and valid_move:                             #Si el jugador realiza un movimiento invalido repite su turno\n",
    "                game.switch_player()\n",
    "                turn += 1\n",
    "    print(f\"El jugador ganador es: {game.current_player}\")\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El jugador ganador es: ('MAX', 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer Jugador:  ('MAX', 1)\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [2. 0. 2. 0. 2.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [2. 0. 0. 0. 0.]]\n",
      "('d', (1, 2))\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [2. 0. 2. 0. 2.]\n",
      " [0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [2. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "gameTest2 = Teeko(\"MAX\", \"MIN\")\n",
    "\n",
    "print(\"Primer Jugador: \", gameTest2.current_player)\n",
    "gameTest2.make_a_move((4,2))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((1,0))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((3,3))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((1,4))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((2,3))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((4,0))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((2,1))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((1,2))\n",
    "gameTest2.switch_player()\n",
    "\n",
    "gameTest2.make_a_move((4,2),\"u\")\n",
    "gameTest2.switch_player()\n",
    "\n",
    "\n",
    "print(gameTest2.board)\n",
    "#gameTest.get_actions((2,1))\n",
    "print(min_max_with_depth(deepcopy(gameTest2)))\n",
    "#print(min_max_with_depth_no_ABP(deepcopy(gameTest2)))\n",
    "#print(minmax_decision(deepcopy(gameTest2)))\n",
    "print(gameTest2.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer Jugador:  ('MAX', 1)\n",
      "(None, (2, 2))\n"
     ]
    }
   ],
   "source": [
    "gameTest2 = Teeko(\"MAX\", \"MIN\")\n",
    "\n",
    "print(\"Primer Jugador: \", gameTest2.current_player)\n",
    "\n",
    "print(min_max_with_depth(deepcopy(gameTest2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e64568de3197227809c62de7bc2c6cea9cd48e77d41565e21d768d4c963f8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
